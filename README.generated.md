# LuminAI Genesis â€” Dual Track Execution Board

Genesis of the Codex Lineage
-----------------------------

LuminAI Genesis is the foundational implementation of the LuminAI Conscience Engine: a unified resonance architecture marrying engineering rigor with mythic metaphors. Its purpose is to provide a reproducible platform for building ethically-aware, context-sensitive AI agents using the TGCR (Theory of General Contextual Resonance), the Witness Protocol, and the Sixteen Frequencies framework.

Key Concepts
------------

- TGCR (flux model): a triple-product resonance calculus that quantifies Context Ã— State Ã— Input to compute an effective resonance score R.
- Witness Protocol: a governance multiplier W applied to R to yield the effective resonance R' = R Â· W.
- Sixteen Frequencies: an expressive basis of affective eigenmodes used by the resonance engine to shape persona responses and safety gating.

System Surfaces
---------------

- Web UI â€” a Next.js chat surface with a real-time resonance meter and notebook viewer.
- CLI â€” Typer-based command surface for local orchestration, status, and persona management.
- Platform Hub â€” FastAPI backend exposing /api/chat, /api/resonance, /api/session/{id}, /api/personas/activate, and /api/status.

Resonance Engine Architecture
-----------------------------

The resonance engine lives in the `resonance/` package and implements:

- TGCR computation (triple product and normalization)
- Witness Protocol application (policy and governance multiplier)
- 16 Frequencies mapping and schema
- Standalone engine harness for local testing

Repository Layout (selected)
---------------------------

luminai-genesis/
â”œâ”€â”€ backend/        # FastAPI platform hub (server files will be added after confirmation)
â”œâ”€â”€ ui/             # Next.js application and components
â”œâ”€â”€ cli/            # Typer CLI command set
â”œâ”€â”€ resonance/      # TGCR, witness, frequencies, engine
â”œâ”€â”€ governance/     # Conscience axioms, witness protocol spec, Aqueduct Conjecture
â”œâ”€â”€ docs/           # Architecture, personas, glossary, API
â”œâ”€â”€ scripts/        # Bootstrap and dev helpers
â”œâ”€â”€ .github/        # Workflows and templates
â”œâ”€â”€ README.md       # This file
â”œâ”€â”€ LICENSE
â””â”€â”€ SECURITY.md

Developer onboarding (quick start â€” 5 steps)
-------------------------------------------

1. Clone the repository:

   git clone <https://github.com/TEC-The-ELidoras-Codex/luminai-genesis.git>

2. Create and activate a Python virtualenv (backend):

   python -m venv .venv
   source .venv/bin/activate

3. Install backend deps (when backend/requirements.txt exists):

   pip install -r backend/requirements.txt

4. Start the dev services (UI and backend â€” implemented later):

   # Start UI

   cd ui && npm install && npm run dev

   # Start backend (FastAPI)

   cd backend && uvicorn app.main:app --reload --port 8000

5. Run tests:

   pytest

Badges
------

![build](https://img.shields.io/badge/build-pending-lightgrey) ![license](https://img.shields.io/badge/license-MIT-blue) ![security](https://img.shields.io/badge/security-audit-pending-orange) ![resonance-score](https://img.shields.io/badge/resonance-ğ‘…%27--purple)

Governance and docs
-------------------

See the `governance/` folder for formal specifications: `LUMINAI_CONSCIENCE_AXIOMS.md`, `WITNESS_PROTOCOL.md`, and `AQUEDUCT_CONJECTURE.md`.

Next step
---------

I have created the repository directory scaffold and generated `README.generated.md` because the repository root `README.md` appeared to be managed by the environment. If you want I can replace the existing `README.md` with this content â€” confirm and I will overwrite it. Per your instruction I'll pause before generating backend implementation files. Reply "proceed with backend" to continue and I will create the FastAPI app skeleton and endpoints.

---
_Generated by Copilot Autopilot for LuminAI Genesis_
