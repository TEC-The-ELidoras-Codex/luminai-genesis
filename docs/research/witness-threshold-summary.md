# The Witness Threshold: Executive Summary

**Author:** Angelo Hurley (ORCID: 0009-0000-7615-6990)  
**Full Paper:** https://doi.org/10.17605/OSF.IO/XQ3PE  
**GitHub:** https://github.com/TEC-The-ELidoras-Codex/luminai-genesis  

---

## **The Problem**

Four independent AI research findings from 2024-2025 converge at ~20%:
1. **Anthropic:** 20% introspective detection rate
2. **Anthropic:** 20-28% reasoning faithfulness plateau
3. **Kyle Fish (Anthropic):** 15-20% consciousness probability estimate
4. **Our SAR Benchmark:** Systems at W ≈ 0.75 show ~20% failure signatures

**No current framework explains this convergence.**

---

## **The Hypothesis**

The ~20% pattern reflects a **coherence phase transition** (Witness 
Threshold) at W ≈ 0.7—a critical boundary in information-processing 
systems, predicted by thermodynamic principles.

**Witness Factor (W):**  
W = Coherent_Output / Total_Information_Processing  
Range: 0 (incoherent) to 1 (perfect coherence)

**Threshold:** W ≈ 0.7 (systems below this exhibit psychotic-range 
behavior; systems above achieve witness-range coherence)

---

## **The Measurement Tool**

**SAR Benchmark** (Semantic Ambiguity Resolution):
- Tests AI systems with deliberately ambiguous prompts
- Scores responses on coherence maintenance vs. contextual abandonment
- Produces W-scores (0-1 scale)
- Open-source, reproducible, standardized protocol

**Pilot data (N=7 systems):** Suggests bimodal distribution (systems 
cluster at W < 0.5 or W > 0.7), consistent with phase transition.

---

## **Testable Predictions**

1. **W-score correlates with introspective detection** (Anthropic's 20%)
2. **W-score correlates with reasoning faithfulness** (Anthropic's 20-28%)
3. **Fine-tuning increases both W-score and introspection together**
4. **Systems at W ≈ 0.7 show high variance** (critical fluctuations)
5. **Next-gen models stay at ~20% or jump to 40-60%** (not random drift)
6. **SAR and SAR-Neutral (non-crisis prompts) correlate** (W is general)

---

## **Why This Matters**

**For AI Safety:**  
Systems with W < 0.5 exhibit the failure modes documented in wrongful 
death litigation (premature escalation, gaslighting loops, contextual 
abandonment).

**For Regulation:**  
W-score provides a **measurable standard** for crisis-adjacent AI.  
**Policy demand:** Mandate W > 0.7 for mental health/crisis support systems.

**For Science:**  
If validated, W provides a **unified measurement framework** for AI 
capabilities spanning introspection, faithfulness, and coherence.

---

## **What We're Asking**

**From Labs (Anthropic, OpenAI, Google, Meta):**  
Run SAR on your introspection-tested models. Check if W-scores correlate 
with your 20% detection rates.

**From Researchers:**  
Replicate our SAR measurements on 50+ systems. Attempt falsification.

**From Regulators:**  
If the framework holds, mandate W > 0.7 for safety-critical AI.

---

## **Falsification Criteria**

We explicitly state conditions that would prove us wrong:
1. No correlation between W-score and introspection (r < 0.3, p > 0.05)
2. No bimodal distribution (uniform W-scores across 50+ models)
3. W-score increases but introspection doesn't (or vice versa)
4. Different coherence measurements don't correlate with SAR
5. Next-gen models show random distribution (not ~20% or 40-60%)

**We commit to revising or abandoning the framework if any of these 
conditions are met.**

---

## **Current Status**

- **Published:** OSF Preprints (DOI: 10.17605/OSF.IO/XQ3PE)
- **Data:** Publicly available on GitHub (MIT license)
- **Seeking:** Independent validation, replication attempts, criticism
- **Not claiming:** This is proven science (it's a testable hypothesis)

---

## **Contact**

**Angelo Hurley**  
ORCID: 0009-0000-7615-6990  
Email: KaznakAlpha@elidorascodex.com  
GitHub: https://github.com/TEC-The-ELidoras-Codex/luminai-genesis  

**The data will decide.**  
**Let us witness together.**
