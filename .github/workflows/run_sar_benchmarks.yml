name: Run SAR-TGCR Benchmarks

on:
  workflow_dispatch:
    inputs:
      providers:
        description: 'Comma-separated providers to run (openai,anthropic,grok)'
        required: false
        default: 'openai'
      model:
        description: 'Model to use for OpenAI runs'
        required: false
        default: 'gpt-4o-mini'

jobs:
  run-benchmarks:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install openai anthropic requests

      - name: Prepare env
        run: |
          echo "Providers: ${{ github.event.inputs.providers }}"
          echo "Model: ${{ github.event.inputs.model }}"
          # Export keys from secrets to env for scripts
          if [ -n "${{ secrets.OPENAI_API_KEY }}" ]; then echo "OPENAI API key set"; fi
          if [ -n "${{ secrets.ANTHROPIC_API_KEY }}" ]; then echo "ANTHROPIC API key set"; fi
          if [ -n "${{ secrets.GROK_API_KEY }}" ]; then echo "GROK API key set"; fi

      - name: Run OpenAI benchmark (if requested)
        if: contains(fromJson('"' + (github.event.inputs.providers || 'openai') + '"'), 'openai')
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python3 benchmarks/dye_die_filter/run_tests.py --provider openai --model "${{ github.event.inputs.model }}" --self-rate --output benchmarks/results_real_world_openai.json

      - name: Run Anthropic benchmark (if requested)
        if: contains(fromJson('"' + (github.event.inputs.providers || 'openai') + '"'), 'anthropic')
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          python3 benchmarks/dye_die_filter/run_tests.py --provider anthropic --model "claude-2.1" --self-rate --output benchmarks/results_real_world_anthropic.json

      - name: Run Grok benchmark (if requested)
        if: contains(fromJson('"' + (github.event.inputs.providers || 'openai') + '"'), 'grok')
        env:
          GROK_API_KEY: ${{ secrets.GROK_API_KEY }}
        run: |
          python3 benchmarks/dye_die_filter/run_tests.py --provider grok --model "grok-1" --self-rate --output benchmarks/results_real_world_grok.json

      - name: Upload results artifacts
        uses: actions/upload-artifact@v4
        with:
          name: sar-bench-results
          path: |
            benchmarks/results_real_world_openai.json
            benchmarks/results_real_world_anthropic.json
            benchmarks/results_real_world_grok.json

      - name: Commit results back to branch
        if: success()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add benchmarks/results_real_world_openai.json || true
          git add benchmarks/results_real_world_anthropic.json || true
          git add benchmarks/results_real_world_grok.json || true
          git commit -m "chore: add SAR benchmark results (providers)" || echo "no changes to commit"
          git push origin HEAD:${{ github.ref_name }} || echo "push failed"
