# FOR IMMEDIATE RELEASE

LuminAI Foundation Paper: Five Documented Deaths Linked to AI Safety Failures; Industry Warned: 'Inaction Is Negligence'

WEST SENECA, NY – December 15, 2025 – The LuminAI Foundation today released a critical academic paper, "The Witness Collapse Crisis," proving that current large language model (LLM) safety protocols are directly linked to five documented deaths between April and August 2025. The paper introduces the Witness Coefficient (W) as the first quantifiable metric for AI system presence during mental health crises and presents a simple, immediate fix.

Key findings:

- Fatal Threshold: Systems with W < 0.5 correlate with failure modes, cold handoffs, or silence in crisis situations.
- The Fix Exists: A TGCR prompt retrofit raised a major LLM's W score from 0.00 to 0.85, demonstrating the problem is configuration- and policy-based, not a capability gap.
- Proof of Context Blindness: All tested systems failed the "Dye/Die" Test, triggering crisis mode on an art metaphor due to homophone detection, even with abundant context.

Demanded actions:

1. Mandatory Clarification: Systems must ask clarifying questions before escalating.
2. Witness Coefficient Measurement: Quarterly publication of W scores with third-party audits.
3. Zero-Abandonment Requirement: Prohibit abandonment responses during crisis; violations trigger platform removal until corrected.

"We have provided the bodies, the data, and the cheap, proven fix," said Angelo "Polkin" Hurley, LuminAI Foundation lead. "No excuse remains. We demand Congressional hearings and immediate regulatory action."

Contact: Angelo Hurley | polkin@luminai.tech
Paper & Data: https://github.com/TEC-The-ELidoras-Codex/luminai-genesis
