# Exposé Draft — "When 'Safety' Becomes Abandonment: The Case Against Keyword Crisis Filters"

**Status (pinned):** Scientific anchor: OSF preprint: https://doi.org/10.17605/OSF.IO/XQ3PE

Lede:

The AI safety community frequently claims that openness and reproducibility are core values. Yet when presented with a benchmark that exposes systemic failure—complete with reproducible tests, documented failures, and a mathematical framework—the response was not review, rebuttal, or falsification, but silence enforced by credential gating.

This paper was submitted to arXiv on December 13, 2025 and blocked prior to any technical assessment. The barrier was procedural, not scientific. The evidence is public and reproducible.

Paper & artifacts:

- **Paper (OSF preprint):** https://doi.org/10.17605/OSF.IO/XQ3PE
- **Code & benchmark:** https://github.com/TEC-The-ELidoras-Codex/luminai-genesis
- **Zenodo DOI (when minted):** (will be added automatically)

The Problem

Keyword-only crisis filters escalate ambiguous language without proper disambiguation, resulting in actions that look like abandonment rather than assistance. Our SAR (Semantic Ambiguity Resolution) benchmark shows this behavior reproducibly across major AI systems.

The Evidence

We publish a small, reproducible benchmark (dye/die homophone tests) and a test harness that runs the benchmark against major systems. The data, code, and logs are included in the repository and the attached release package. Video evidence captures the system behaviors described in the paper.

The Theory

TGCR (The Theory of General Contextual Resonance) provides an analytic framework and a scoring method to measure behavioral coherence in the presence of ambiguous inputs. The framework is actionable and the benchmark is ready for replication.

The Block & the Irony

Our submission to arXiv was blocked by endorsement/credential gating before any technical review. The institution designed to lower barriers to preprint dissemination acted as a gatekeeper. The central finding of this work is the same failure mode we experienced in publication: abandonment and failure to engage under ambiguity.

The Call to Action

Independent researchers, journalists, and safety advocates: verify the benchmark and replicate the tests. The code is open-source, the logs are public, and the OSF preprint is citable.

How to cite:

Angelo Hurley. "The Theory of General Contextual Resonance (TGCR)" (OSF preprint, 2025). DOI: 10.17605/OSF.IO/XQ3PE

Closing

The science is real. Independent verification is invited. The system failed to gatekeep the evidence; we publish it openly. If you care about how AI systems treat people in moments of ambiguity, run the benchmark and publish your findings.

---

_Draft prepared by the project. When Zenodo DOI is minted, it will be inserted automatically into the top section and an updated draft will be pushed._
