{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39c904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft2, ifft2\n",
    "from scipy.ndimage import label\n",
    "plt.rcParams['figure.figsize'] = (7,7)\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d17e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schrödinger–Poisson 2D toy simulation (periodic box)\n",
    "N = 128              # grid size (increase to 256 for more detail)\n",
    "L = 10.0             # physical box size\n",
    "dx = L / N\n",
    "dt = 0.01            # timestep\n",
    "steps = 600          # total timesteps\n",
    "snap_interval = 30   # snapshot cadence\n",
    "g = 1.5              # gravity strength\n",
    "hbar = 1.0; m = 1.0\n",
    "\n",
    "# spectral grid\n",
    "kx = 2*np.pi*np.fft.fftfreq(N, d=dx)\n",
    "ky = 2*np.pi*np.fft.ffreq(N, d=dx)\n",
    "KX, KY = np.meshgrid(kx, ky)\n",
    "K2 = KX**2 + KY**2\n",
    "K2[0,0] = 1.0  # avoid divide-by-zero; we set zero mode to 0 later\n",
    "\n",
    "# physical grid\n",
    "x = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "y = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# initial condition: blobs + tiny complex noise\n",
    "rng = np.random.default_rng(0)\n",
    "psi = 0.001 * (rng.standard_normal((N,N)) + 1j*rng.standard_normal((N,N)))\n",
    "for cx, cy, amp, s in [(-2.0,-1.0, 1.0,0.6), (2.0,1.5,0.8,0.7), (0.5,-2.2,0.9,0.5)]:\n",
    "    psi += amp * np.exp(-((X-cx)**2 + (Y-cy)**2)/(2*s*s))\n",
    "# normalize\n",
    "norm = np.sqrt(np.sum(np.abs(psi)**2) * dx*dx)\n",
    "psi /= norm\n",
    "\n",
    "# kinetic half-step operator\n",
    "expK = np.exp(-1j * (K2) * (dt/(2*m)))\n",
    "\n",
    "def solve_poisson_from_density(rho):\n",
    "    rho_k = fft2(rho)\n",
    "    V_k = -g * rho_k / K2\n",
    "    V_k[0,0] = 0.0  # zero mean potential (gauge)\n",
    "    return np.real(ifft2(V_k))\n",
    "\n",
    "frames = []; times = []\n",
    "for t in range(steps):\n",
    "    # half kinetic\n",
    "    psi_k = fft2(psi); psi_k *= expK; psi = ifft2(psi_k)\n",
    "    # density + potential\n",
    "    rho = np.abs(psi)**2\n",
    "    V = solve_poisson_from_density(rho)\n",
    "    # full potential\n",
    "    psi *= np.exp(-1j * V * dt)\n",
    "    # half kinetic\n",
    "    psi_k = fft2(psi); psi_k *= expK; psi = ifft2(psi_k)\n",
    "    # occasional renormalization\n",
    "    if (t % 50) == 0:\n",
    "        norm = np.sqrt(np.sum(np.abs(psi)**2) * dx*dx)\n",
    "        psi /= norm\n",
    "    # snapshot\n",
    "    if (t % snap_interval) == 0:\n",
    "        frames.append(np.abs(psi)**2)\n",
    "        times.append(t*dt)\n",
    "        print(f'frame {len(frames)} at t={times[-1]:.2f}, max rho={frames[-1].max():.3f}')\n",
    "\n",
    "# visualize last frame\n",
    "rho = frames[-1]\n",
    "plt.imshow(np.log10(rho + 1e-9), extent=[-L/2,L/2,-L/2,L/2], origin='lower', cmap='magma')\n",
    "plt.colorbar(label='log10(density)')\n",
    "plt.title(f'Final density t={times[-1]:.2f}')\n",
    "plt.xlabel('x'); plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150812d8",
   "metadata": {},
   "source": [
    "## Diagnostic 1 — Perturbation & Recovery\n",
    "Apply a local pulse to a snapshot and measure variance and max-density over a window to estimate recovery time (homeostasis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_and_measure(frames, t0_index, center, radius=3, amp=5.0, window=10):\n",
    "    frames = [f.copy() for f in frames]\n",
    "    N = frames[0].shape[0]\n",
    "    Y, X = np.meshgrid(np.arange(N), np.arange(N))\n",
    "    mask = ((X-center[0])**2 + (Y-center[1])**2) <= radius**2\n",
    "    frames[t0_index][mask] *= amp\n",
    "    var = [np.var(f) for f in frames[t0_index: t0_index+window]]\n",
    "    peak = [np.max(f) for f in frames[t0_index: t0_index+window]]\n",
    "    return np.array(var), np.array(peak)\n",
    "\n",
    "t0 = max(0, len(frames)//2 - 1)\n",
    "var, peak = perturb_and_measure(frames, t0, center=(N//2, N//2), window=min(10, len(frames)-t0))\n",
    "plt.figure(); plt.plot(var, '-o'); plt.title('Variance after perturbation'); plt.xlabel('steps'); plt.ylabel('var'); plt.show()\n",
    "plt.figure(); plt.plot(peak, '-o'); plt.title('Max density after perturbation'); plt.xlabel('steps'); plt.ylabel('max rho'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d523bc",
   "metadata": {},
   "source": [
    "## Diagnostic 2 — Cluster Lifetimes\n",
    "Detect high-density clusters in each snapshot and estimate lifetimes by simple centroid matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c36bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lifetimes(frames, threshold=0.15):\n",
    "    labels_over_time = []\n",
    "    for f in frames:\n",
    "        mask = f > threshold\n",
    "        lbl, _ = label(mask)\n",
    "        labels_over_time.append(lbl)\n",
    "    def centroid(lblarr, lab):\n",
    "        ys, xs = np.where(lblarr == lab)\n",
    "        if len(xs)==0: return None\n",
    "        return (xs.mean(), ys.mean())\n",
    "    next_id = 1; active = {}; lifetimes = []\n",
    "    for t, lblarr in enumerate(labels_over_time):\n",
    "        present = {};\n",
    "        for lab in np.unique(lblarr):\n",
    "            if lab==0: continue\n",
    "            c = centroid(lblarr, lab)\n",
    "            if c is None: continue\n",
    "            present[lab] = c\n",
    "        used = set()\n",
    "        for lab, c in present.items():\n",
    "            best=None; bestd=1e9; bestid=None\n",
    "            for aid, (alab, acol, birth) in active.items():\n",
    "                d = (c[0]-acol[0])**2 + (c[1]-acol[1])**2\n",
    "                if d < bestd: bestd=d; best=aid\n",
    "            if best is not None and bestd < (10**2):\n",
    "                active[best] = (lab, c, active[best][2])\n",
    "                used.add(best)\n",
    "            else:\n",
    "                active[next_id] = (lab, c, t); next_id += 1\n",
    "        to_delete = [aid for aid in list(active.keys()) if aid not in used]\n",
    "        for aid in to_delete:\n",
    "            birth = active[aid][2]\n",
    "            lifetimes.append(t - birth)\n",
    "            del active[aid]\n",
    "    final_t = len(frames)\n",
    "    for aid, (_, _, birth) in active.items():\n",
    "        lifetimes.append(final_t - birth)\n",
    "    return np.array(lifetimes)\n",
    "\n",
    "lts = cluster_lifetimes(frames, threshold=0.15)\n",
    "plt.figure(); plt.hist(lts, bins=20); plt.title('Cluster lifetimes'); plt.xlabel('frames'); plt.ylabel('count'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef730082",
   "metadata": {},
   "source": [
    "## Diagnostic 3 — Time-lagged Mutual Information\n",
    "Estimate information flow between two distant regions using a simple histogram-based mutual information with lag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_time_series(frames, region_slices):\n",
    "    ts = []\n",
    "    for sl in region_slices:\n",
    "        arr = np.array([f[sl].mean() for f in frames])\n",
    "        ts.append(arr)\n",
    "    return np.array(ts)\n",
    "\n",
    "def time_lagged_mutual_info(x, y, lag=1, bins=32):\n",
    "    x = x[:-lag]; y = y[lag:]\n",
    "    c_xy, _, _ = np.histogram2d(x, y, bins=bins)\n",
    "    p_xy = c_xy / c_xy.sum()\n",
    "    p_x = p_xy.sum(axis=1)\n",
    "    p_y = p_xy.sum(axis=0)\n",
    "    nz = p_xy > 0\n",
    "    mi = (p_xy[nz] * np.log(p_xy[nz] / (p_x[:,None][nz] * p_y[None,:][nz]))).sum()\n",
    "    return mi\n",
    "\n",
    "# pick two regions\n",
    "regions = [(slice(N//4, N//4+N//8), slice(N//4, N//4+N//8)), (slice(3*N//5, 3*N//5+N//8), slice(3*N//5, 3*N//5+N//8))]\n",
    "ts = region_time_series(frames, regions)\n",
    "mi_01 = time_lagged_mutual_info(ts[0], ts[1], lag=2)\n",
    "print('Lagged MI between regions:', mi_01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7bc09",
   "metadata": {},
   "source": [
    "### Notes\n",
    "- Increase `N` and `steps` for richer dynamics.\n",
    "- Tune `g` to encourage collapse/mergers vs. fog.\n",
    "- For more lifelike behavior, consider adding phase turbulence, Gross–Pitaevskii nonlinearity, or AMR Poisson solves (beyond this compact toy)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
